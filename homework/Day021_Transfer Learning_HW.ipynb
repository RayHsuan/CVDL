{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 使用Xception backbone做 Trnasfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 了解如何使用Transfer Learning\n",
    "  #### 了解Transfer Learning的優點，可以觀察模型收斂速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 可以自行嘗試多種架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 15, 15, 32)   864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 15, 15, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 15, 15, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 13, 13, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 13, 13, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 13, 13, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 13, 13, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 13, 13, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 13, 13, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 128)    8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 7, 7, 128)    0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7, 7, 128)    512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 7, 7, 128)    0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 7, 7, 128)    0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 7, 7, 256)    33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 7, 7, 256)    0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 7, 7, 256)    67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 256)    32768       add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4, 4, 256)    1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 4, 4, 256)    0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 4, 4, 256)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 4, 4, 728)    188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 4, 4, 728)    0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 2, 2, 728)    186368      add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 2, 2, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 2, 2, 728)    2912        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 2, 2, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 2, 2, 728)    0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 2, 2, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 2, 2, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 2, 2, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 2, 2, 728)    0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 2, 2, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 2, 2, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 2, 2, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 2, 2, 728)    0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 2, 2, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 2, 2, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 2, 2, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 2, 2, 728)    0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 2, 2, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 2, 2, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 2, 2, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 2, 2, 728)    0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 2, 2, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 2, 2, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 2, 2, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 2, 2, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 2, 2, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 2, 2, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 2, 2, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 2, 2, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 2, 2, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 2, 2, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 2, 2, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 2, 2, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 2, 2, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 2, 2, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 2, 2, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 1024)   745472      add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 1, 1, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 1, 1024)   4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 1, 1, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 1, 1, 1536)   1582080     add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 1, 1, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 1, 1, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 1, 1, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 1, 1, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 1, 1, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.layers import Input\n",
    " \n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "#include top 決定要不要加入 fully Connected Layer\n",
    "\n",
    "'''Xception 架構'''\n",
    "model = keras.applications.xception.Xception(include_top=False, weights='imagenet', \n",
    "                                             input_tensor=input_tensor,\n",
    "                                             pooling=None, classes=1000)\n",
    "'''Resnet 50 架構'''\n",
    "#model=keras.applications.ResNet50(include_top=False, weights='imagenet',\n",
    "                                    #input_tensor=input_tensor,\n",
    "                                    #pooling=None, classes=10)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加層數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model深度： 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \"\"\"\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x = model.output\n",
    "\n",
    "'''可以參考Cifar10實作章節'''\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(output_dim=128, activation='relu')(x)\n",
    "x=Dropout(p=0.1)(x)\n",
    "\n",
    "predictions = Dense(output_dim=10,activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "print('Model深度：', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 鎖定特定幾層不要更新權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[100:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備 Cifar 10 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1224 00:07:55.897131 16892 deprecation_wrapper.py:119] From C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1224 00:07:56.036758 16892 deprecation.py:323] From C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 45s 892us/step - loss: 1.3868 - acc: 0.5170\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 37s 731us/step - loss: 1.0095 - acc: 0.6562\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 37s 731us/step - loss: 0.9023 - acc: 0.6896\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 36s 724us/step - loss: 0.8214 - acc: 0.7147\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 36s 730us/step - loss: 0.7435 - acc: 0.7452\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 0.6792 - acc: 0.7671\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 0.6098 - acc: 0.7896\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 0.5446 - acc: 0.8120\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 35s 702us/step - loss: 0.4961 - acc: 0.8303\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 0.4508 - acc: 0.8456\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 35s 704us/step - loss: 0.4032 - acc: 0.8612\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 37s 748us/step - loss: 0.3638 - acc: 0.8757\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 37s 747us/step - loss: 0.3402 - acc: 0.8842\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.3200 - acc: 0.8914\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.2931 - acc: 0.8998\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 36s 719us/step - loss: 0.2798 - acc: 0.9051\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.2610 - acc: 0.9108\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 36s 726us/step - loss: 0.2486 - acc: 0.9157\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 37s 733us/step - loss: 0.2374 - acc: 0.9191\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 36s 729us/step - loss: 0.2256 - acc: 0.9254\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 37s 733us/step - loss: 0.2137 - acc: 0.9270\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 36s 723us/step - loss: 0.2096 - acc: 0.9280\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 36s 721us/step - loss: 0.1991 - acc: 0.9335\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 36s 714us/step - loss: 0.1971 - acc: 0.9324\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 35s 704us/step - loss: 0.1801 - acc: 0.9385\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 0.1824 - acc: 0.9390\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 35s 708us/step - loss: 0.1723 - acc: 0.9416\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 35s 705us/step - loss: 0.1655 - acc: 0.9438\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 36s 719us/step - loss: 0.1684 - acc: 0.9434\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 36s 725us/step - loss: 0.1601 - acc: 0.9457\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 0.1533 - acc: 0.9486\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.1514 - acc: 0.9498\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.1468 - acc: 0.9503\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.1419 - acc: 0.9511\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1374 - acc: 0.9546\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.1357 - acc: 0.9540\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.1345 - acc: 0.9549\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 0.1312 - acc: 0.9563\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.1303 - acc: 0.9572\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 0.1247 - acc: 0.9582\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.1233 - acc: 0.9589\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1219 - acc: 0.9592\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 37s 737us/step - loss: 0.1190 - acc: 0.9608\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 37s 746us/step - loss: 0.1167 - acc: 0.9617\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.1124 - acc: 0.9620\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 0.1131 - acc: 0.9633\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 37s 737us/step - loss: 0.1066 - acc: 0.9649\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 35s 707us/step - loss: 0.1045 - acc: 0.9660\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 35s 705us/step - loss: 0.1047 - acc: 0.9650\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 35s 706us/step - loss: 0.1064 - acc: 0.9652\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 35s 706us/step - loss: 0.0993 - acc: 0.9671\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 35s 706us/step - loss: 0.1014 - acc: 0.9661\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 36s 712us/step - loss: 0.1043 - acc: 0.9658\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.0983 - acc: 0.9671\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.0941 - acc: 0.9693\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.0969 - acc: 0.9681\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.0918 - acc: 0.9696\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 37s 737us/step - loss: 0.0941 - acc: 0.9693\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.0906 - acc: 0.9706\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.0881 - acc: 0.9713\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.0894 - acc: 0.9705\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 0.0881 - acc: 0.9712\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 0.0865 - acc: 0.9719\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 37s 735us/step - loss: 0.0850 - acc: 0.9716\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.0855 - acc: 0.9722\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.0835 - acc: 0.9729\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.0810 - acc: 0.9730\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.0809 - acc: 0.9737\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.0822 - acc: 0.9741\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 0.0765 - acc: 0.9746\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.0813 - acc: 0.9737\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.0766 - acc: 0.9748\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.0783 - acc: 0.9740\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.0732 - acc: 0.9751\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.0769 - acc: 0.9746\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 38s 755us/step - loss: 0.0735 - acc: 0.9761\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.0743 - acc: 0.9755\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.0722 - acc: 0.9765\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 37s 744us/step - loss: 0.0704 - acc: 0.9773\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.0729 - acc: 0.9759\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.0671 - acc: 0.9779\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 37s 750us/step - loss: 0.0729 - acc: 0.9772\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.0676 - acc: 0.9777\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.0662 - acc: 0.9788\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 37s 737us/step - loss: 0.0680 - acc: 0.9779\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 0.0651 - acc: 0.9788\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.0668 - acc: 0.9785\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 37s 737us/step - loss: 0.0689 - acc: 0.9776\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 37s 737us/step - loss: 0.0625 - acc: 0.9800\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 0.0639 - acc: 0.9796\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 0.0666 - acc: 0.9787\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 37s 735us/step - loss: 0.0650 - acc: 0.9795\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.0626 - acc: 0.9811\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.0644 - acc: 0.9797\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.0619 - acc: 0.9802\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 37s 750us/step - loss: 0.0622 - acc: 0.9804\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.0623 - acc: 0.9801\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 37s 746us/step - loss: 0.0606 - acc: 0.9795\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 37s 745us/step - loss: 0.0559 - acc: 0.9823\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 37s 745us/step - loss: 0.0575 - acc: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23a68616dc8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
