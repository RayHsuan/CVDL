{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250015840000.0\n",
      "\n",
      "\n",
      "\n",
      "Shape: (10000, 10000) Device: /gpu:0\n",
      "Time taken: 0:00:21.331618\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    " \n",
    "device_name=\"/gpu:0\"\n",
    " \n",
    "shape=(int(10000),int(10000))\n",
    " \n",
    "with tf.device(device_name):\n",
    "    #形状为shap,元素服从minval和maxval之间的均匀分布\n",
    "    random_matrix = tf.random_uniform(shape=shape, minval=0, maxval=1)\n",
    "    dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n",
    "    sum_operation = tf.reduce_sum(dot_operation)\n",
    "startTime = datetime.now()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "    result = session.run(sum_operation)\n",
    "    print(result)\n",
    "    print(\"\\n\" * 2)\n",
    "print(\"Shape:\", shape, \"Device:\", device_name)\n",
    "print(\"Time taken:\", datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpu:0   size= 0  Time: 0.07183051109313965\n",
      "/cpu:0   size= 0  Time: 0.05189013481140137\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 500  Time: 0.05241537094116211\n",
      "/cpu:0   size= 500  Time: 0.054853200912475586\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 1000  Time: 0.05285811424255371\n",
      "/cpu:0   size= 1000  Time: 0.07083678245544434\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 1500  Time: 0.06045389175415039\n",
      "/cpu:0   size= 1500  Time: 0.09005546569824219\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 2000  Time: 0.06182980537414551\n",
      "/cpu:0   size= 2000  Time: 0.11666488647460938\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 2500  Time: 0.05681872367858887\n",
      "/cpu:0   size= 2500  Time: 0.1521003246307373\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 3000  Time: 0.0578458309173584\n",
      "/cpu:0   size= 3000  Time: 0.21841645240783691\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 3500  Time: 0.06382989883422852\n",
      "/cpu:0   size= 3500  Time: 0.2877368927001953\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 4000  Time: 0.07081103324890137\n",
      "/cpu:0   size= 4000  Time: 0.38399553298950195\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 4500  Time: 0.07486653327941895\n",
      "/cpu:0   size= 4500  Time: 0.47969818115234375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 5000  Time: 0.08477377891540527\n",
      "/cpu:0   size= 5000  Time: 0.6268014907836914\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 5500  Time: 0.09477853775024414\n",
      "/cpu:0   size= 5500  Time: 0.7838802337646484\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 6000  Time: 0.11372137069702148\n",
      "/cpu:0   size= 6000  Time: 0.9793808460235596\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 6500  Time: 0.12464237213134766\n",
      "/cpu:0   size= 6500  Time: 1.1808428764343262\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 7000  Time: 0.1475818157196045\n",
      "/cpu:0   size= 7000  Time: 1.4692108631134033\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 7500  Time: 0.15713715553283691\n",
      "/cpu:0   size= 7500  Time: 1.7503445148468018\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 8000  Time: 0.18149280548095703\n",
      "/cpu:0   size= 8000  Time: 2.1652822494506836\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 8500  Time: 0.21143484115600586\n",
      "/cpu:0   size= 8500  Time: 2.3986103534698486\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 9000  Time: 0.24038434028625488\n",
      "/cpu:0   size= 9000  Time: 2.8923370838165283\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/gpu:0   size= 9500  Time: 0.27427029609680176\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2420c5b9cd41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mTestGpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDeviceTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/gpu:0\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mTestCpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDeviceTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-2420c5b9cd41>\u001b[0m in \u001b[0;36mDeviceTest\u001b[1;34m(device_name, size)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtake_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def DeviceTest(device_name,size):\n",
    "    with tf.device(device_name):       \n",
    "        M1=tf.random_normal([size,size],name='M1')\n",
    "        M2=tf.random_normal([size,size],name='M2')\n",
    "        mul=tf.matmul(M1,M2,name='mul')\n",
    "        sum_result=tf.reduce_sum(mul,name='sum_result')\n",
    "        \n",
    "\n",
    "        start_time=time.time()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            result=sess.run(sum_result)\n",
    "        \n",
    "        take_time=time.time()-start_time       \n",
    "        print(device_name,\"  size=\",size, \" Time:\",take_time)\n",
    "        \n",
    "        return take_time  #這樣append到SET才有東西\n",
    "    \n",
    "Gpu_Set=[];  Cpu_set=[];  Size_set=[]\n",
    "\n",
    "for i in range(0,10001,500):\n",
    "    TestGpu=DeviceTest(\"/gpu:0\",i)\n",
    "    TestCpu=DeviceTest(\"/cpu:0\",i)\n",
    "    \n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    Gpu_Set.append(TestGpu)\n",
    "    Cpu_set.append(TestCpu)\n",
    "    Size_set.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU computation time: 0:00:05.560438\n",
      "Multi GPU computation time: 0:00:02.501978\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This tutorial requires your machine to have 2 GPUs\n",
    "\"/cpu:0\": The CPU of your machine.\n",
    "\"/gpu:0\": The first GPU of your machine\n",
    "\"/gpu:1\": The second GPU of your machine\n",
    "'''\n",
    " \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    " \n",
    "# Processing Units logs\n",
    "log_device_placement = True\n",
    " \n",
    "# Num of multiplications to perform\n",
    "n = 10\n",
    " \n",
    "'''\n",
    "Example: compute A^n + B^n on 2 GPUs\n",
    "Results on  2 RTX-:\n",
    " * Single GPU computation time: 0:00:??\n",
    " * Multi GPU computation time: 0:00:??\n",
    "'''\n",
    "# Create random large matrix\n",
    "A = np.random.rand(10000, 10000).astype('float32')\n",
    "B = np.random.rand(10000, 10000).astype('float32')\n",
    " \n",
    "# Create a graph to store results\n",
    "c1 = []\n",
    "c2 = []\n",
    " \n",
    "def matpow(M, n):\n",
    "    if n < 1: #Abstract cases where n < 1\n",
    "        return M\n",
    "    else:\n",
    "        return tf.matmul(M, matpow(M, n-1))\n",
    "\n",
    "'''\n",
    "Single GPU computing\n",
    "'''\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    b = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    # Compute A^n and B^n and store results in c1\n",
    "    c1.append(matpow(a, n))\n",
    "    c1.append(matpow(b, n))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c1) #Addition of all elements in c1, i.e. A^n + B^n\n",
    "\n",
    "t1_1 = datetime.datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n",
    "    # Run the op.\n",
    "    sess.run(sum, {a:A, b:B})\n",
    "t2_1 = datetime.datetime.now()\n",
    " \n",
    "\n",
    "'''\n",
    "Multi GPU computing\n",
    "'''\n",
    "# GPU:0 computes A^n\n",
    "with tf.device('/gpu:0'):\n",
    "    # Compute A^n and store result in c2\n",
    "    a = tf.placeholder(tf.float32, [10000, 10000])\n",
    "    c2.append(matpow(a, n))\n",
    "\n",
    "# GPU:1 computes B^n\n",
    "#with tf.device('/gpu:1'):\n",
    "    # Compute B^n and store result in c2\n",
    "#    b = tf.placeholder(tf.float32, [10000, 10000])\n",
    "#    c2.append(matpow(b, n))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c2) #Addition of all elements in c2, i.e. A^n + B^n\n",
    "\n",
    "t1_2 = datetime.datetime.now()\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:\n",
    "    # Run the op.\n",
    "    sess.run(sum, {a:A, b:B})\n",
    "t2_2 = datetime.datetime.now()\n",
    " \n",
    "print(\"Single GPU computation time: \" + str(t2_1-t1_1))\n",
    "print(\"Multi GPU computation time: \" + str(t2_2-t1_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "    mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "    X_train = (X_train-mean)/(std+1e-7)\n",
    "    X_test = (X_test-mean)/(std+1e-7) \n",
    "    return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.01)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.4092 - acc: 0.5687\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.0340 - acc: 0.6912\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.8876 - acc: 0.7391\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.8047 - acc: 0.7668\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.7411 - acc: 0.7906\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6948 - acc: 0.8108\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.6543 - acc: 0.8307\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.6222 - acc: 0.8435\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.5892 - acc: 0.8591\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.5646 - acc: 0.8707\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.5467 - acc: 0.8783\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.5327 - acc: 0.8871\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.5210 - acc: 0.8911\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.5006 - acc: 0.8995\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4844 - acc: 0.9066\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4904 - acc: 0.9067\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4850 - acc: 0.9097\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4692 - acc: 0.9164\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4654 - acc: 0.9183\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4630 - acc: 0.9182\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4664 - acc: 0.9193\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4560 - acc: 0.9253\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4435 - acc: 0.9286\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4546 - acc: 0.9250\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4495 - acc: 0.9284\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.4464 - acc: 0.9294\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.4478 - acc: 0.9295\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4383 - acc: 0.9323\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4434 - acc: 0.9317\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4385 - acc: 0.9334\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4329 - acc: 0.9360\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4435 - acc: 0.9314\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4355 - acc: 0.9359\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4287 - acc: 0.9378\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4272 - acc: 0.9382\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4347 - acc: 0.9358\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4308 - acc: 0.9392\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4258 - acc: 0.9395\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.4256 - acc: 0.9397\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4259 - acc: 0.9397\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4192 - acc: 0.9412\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4204 - acc: 0.9422\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4227 - acc: 0.9418\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4287 - acc: 0.9400\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.4238 - acc: 0.9417\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.4208 - acc: 0.9434\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4171 - acc: 0.9433\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4102 - acc: 0.9445\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4179 - acc: 0.9424\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4268 - acc: 0.9403\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4191 - acc: 0.9444\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4042 - acc: 0.9476\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4154 - acc: 0.9435\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4262 - acc: 0.9412\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4023 - acc: 0.9491\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4031 - acc: 0.9462\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4279 - acc: 0.9408\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4071 - acc: 0.9473\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.3992 - acc: 0.9494\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4093 - acc: 0.9452\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4058 - acc: 0.9469\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4089 - acc: 0.9466\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4060 - acc: 0.9469\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4043 - acc: 0.9483\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4077 - acc: 0.9463\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4067 - acc: 0.9474\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4075 - acc: 0.9476\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4056 - acc: 0.9485\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.3996 - acc: 0.9494\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.4062 - acc: 0.9468\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.4000 - acc: 0.9494\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.3934 - acc: 0.9514\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.4040 - acc: 0.9478\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.4006 - acc: 0.9481\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.3964 - acc: 0.9500\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.3945 - acc: 0.9504\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4004 - acc: 0.9482\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4099 - acc: 0.9468\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4016 - acc: 0.9500\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.3985 - acc: 0.9504\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.3882 - acc: 0.9529\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.3920 - acc: 0.9509\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.3921 - acc: 0.9500\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.4013 - acc: 0.9476\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.3933 - acc: 0.9513\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.3905 - acc: 0.9517\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.3930 - acc: 0.9508\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.3922 - acc: 0.9509\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 0.3843 - acc: 0.9538\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 0.3982 - acc: 0.9484\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.3922 - acc: 0.9515\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 0.3959 - acc: 0.9511\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.3835 - acc: 0.9540\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.3856 - acc: 0.9517\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.3922 - acc: 0.9508\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.3849 - acc: 0.9524\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.3934 - acc: 0.9511\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.3839 - acc: 0.9538\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 0.3828 - acc: 0.9543\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 0.3928 - acc: 0.9508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23568721e88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64, (3,3), padding='same',input_shape=(32,32,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, (3,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=100,activation='relu',kernel_regularizer=regularizers.l2(l=0.001)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(p=0.01))\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.3707012e-02, 9.4767461e-07, 2.0855308e-01, 4.2585623e-01,\n",
       "        1.3898586e-01, 3.5427327e-06, 2.1875611e-02, 8.8977540e-06,\n",
       "        1.2100813e-01, 7.0388199e-07]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.5770905710220338\n",
      "Test accuracy: 0.7321\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=100)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               409700    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 487,562\n",
      "Trainable params: 486,970\n",
      "Non-trainable params: 592\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, (3, 3), padding='same',input_shape=(32,32,3), activation='relu'))\n",
    "classifier.add(Convolution2D(32, (3, 3), padding='same', activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64, (3, 3), padding='same', activation='relu'))\n",
    "classifier.add(Convolution2D(64, (3, 3), padding='same', activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=100,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "classifier.add(BatchNormalization()) \n",
    "classifier.add(Dropout(p=0.5))\n",
    "\n",
    "classifier.add(Dense(output_dim=100,activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "classifier.add(BatchNormalization()) \n",
    "classifier.add(Dropout(p=0.1))\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation= 'softmax'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 9s 190us/step - loss: 2.4190 - acc: 0.4660\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.4523 - acc: 0.6396\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.3120 - acc: 0.6956\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.2201 - acc: 0.7267\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.1703 - acc: 0.7466\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.1256 - acc: 0.7648\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.0866 - acc: 0.7767\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.0612 - acc: 0.7872\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.0344 - acc: 0.7948\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.0127 - acc: 0.8031\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.9906 - acc: 0.8135\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.9693 - acc: 0.8211\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.9587 - acc: 0.8260\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.9345 - acc: 0.8314\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.9351 - acc: 0.8324\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.9162 - acc: 0.8406\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.8913 - acc: 0.8476\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.8911 - acc: 0.8478\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.8753 - acc: 0.8554\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.8745 - acc: 0.8572\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.8665 - acc: 0.8610\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.8463 - acc: 0.8660\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.8431 - acc: 0.8704\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.8425 - acc: 0.8707\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.8291 - acc: 0.8746\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.8255 - acc: 0.8784\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.8118 - acc: 0.8815\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.8161 - acc: 0.8793\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.8045 - acc: 0.8854\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.7983 - acc: 0.8859\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.7935 - acc: 0.8888\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.7808 - acc: 0.8929\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.7818 - acc: 0.8959\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.7755 - acc: 0.8952\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.7755 - acc: 0.8963\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.7611 - acc: 0.9004\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7612 - acc: 0.9003\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7543 - acc: 0.9027\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.7613 - acc: 0.9010\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7433 - acc: 0.9058\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7448 - acc: 0.9073\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.7372 - acc: 0.9091\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.7342 - acc: 0.9085\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.7371 - acc: 0.9099\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7218 - acc: 0.9136\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7208 - acc: 0.9133\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7168 - acc: 0.9150\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7247 - acc: 0.9144\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7058 - acc: 0.9176\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7099 - acc: 0.9167\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7141 - acc: 0.9156\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.6991 - acc: 0.9214\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.7088 - acc: 0.9202\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7013 - acc: 0.9224\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.7088 - acc: 0.9202\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.6864 - acc: 0.9243\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.6889 - acc: 0.9223\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.6879 - acc: 0.9230\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.6997 - acc: 0.9228\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.6824 - acc: 0.9259\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.6761 - acc: 0.9277\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.6814 - acc: 0.9277\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6847 - acc: 0.9280\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.6704 - acc: 0.9287\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.6710 - acc: 0.9292\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.6657 - acc: 0.9305\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6658 - acc: 0.9307\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.6689 - acc: 0.9312\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6566 - acc: 0.9328\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6718 - acc: 0.9319\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6537 - acc: 0.9330\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6598 - acc: 0.9332\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6533 - acc: 0.9346\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6642 - acc: 0.9339\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6520 - acc: 0.9346\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6506 - acc: 0.9360\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.6563 - acc: 0.9346\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.6358 - acc: 0.9363\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.6566 - acc: 0.9362\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6464 - acc: 0.9381\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6418 - acc: 0.9378\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6430 - acc: 0.9377\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6398 - acc: 0.9382\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6404 - acc: 0.9382\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6378 - acc: 0.9389\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6279 - acc: 0.9404\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6480 - acc: 0.9380\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.6268 - acc: 0.9410\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6231 - acc: 0.9414\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6207 - acc: 0.9423\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6173 - acc: 0.9427\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6237 - acc: 0.9406\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6200 - acc: 0.9414\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6208 - acc: 0.9428\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6116 - acc: 0.9435\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6148 - acc: 0.9438\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6184 - acc: 0.9434\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6184 - acc: 0.9423\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6053 - acc: 0.9441\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.6067 - acc: 0.9450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235683e5f48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27999887, 0.00196995, 0.05890363, 0.27287757, 0.20220275,\n",
       "        0.00490784, 0.02788561, 0.00643734, 0.13682283, 0.00799367]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.3867085874557494\n",
      "Test accuracy: 0.785\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=128)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=256)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 15, 15, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 422,826\n",
      "Trainable params: 421,354\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.3)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", kernel_regularizer=<keras.reg..., units=128)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, (3, 3), padding='same',input_shape=(32,32,3), activation='relu'))\n",
    "classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64, (3, 3), padding='same', activation='relu'))\n",
    "classifier.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(128, (3, 3), padding='same', activation='relu'))\n",
    "classifier.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=128,activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "classifier.add(BatchNormalization()) \n",
    "classifier.add(Dropout(p=0.5))\n",
    "\n",
    "classifier.add(Dense(output_dim=256,activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "classifier.add(BatchNormalization()) \n",
    "classifier.add(Dropout(p=0.3))\n",
    "\n",
    "classifier.add(Dense(output_dim=128,activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "classifier.add(BatchNormalization()) \n",
    "classifier.add(Dropout(p=0.5))\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation= 'softmax'))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 2.4338 - acc: 0.3451\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.6880 - acc: 0.5467\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.3268 - acc: 0.6458\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.0753 - acc: 0.7106\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.9139 - acc: 0.7496\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.8029 - acc: 0.7781\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.7124 - acc: 0.8048\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.6446 - acc: 0.8251\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.5974 - acc: 0.8401\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.5495 - acc: 0.8536\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.5109 - acc: 0.8681\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.4758 - acc: 0.8787\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.4321 - acc: 0.8956\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.4052 - acc: 0.9040\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.3753 - acc: 0.9125\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.3597 - acc: 0.9185\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.3420 - acc: 0.9235\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.3187 - acc: 0.9302\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.3036 - acc: 0.9345\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.2894 - acc: 0.9391\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 0.2833 - acc: 0.9416\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.2641 - acc: 0.9478\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.2511 - acc: 0.9506\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.2475 - acc: 0.9532\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.2370 - acc: 0.9551\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.2373 - acc: 0.9557\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.2231 - acc: 0.9593\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.2203 - acc: 0.9597\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.2140 - acc: 0.9621\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.2106 - acc: 0.9628\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.2116 - acc: 0.9630\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.2008 - acc: 0.9664\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1951 - acc: 0.9682\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1998 - acc: 0.9659\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.2019 - acc: 0.9662\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.1858 - acc: 0.9696\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1822 - acc: 0.9709\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1752 - acc: 0.9726\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1849 - acc: 0.9702\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1755 - acc: 0.9730\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1798 - acc: 0.9713\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1721 - acc: 0.9740\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1715 - acc: 0.9739\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1748 - acc: 0.9736\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1615 - acc: 0.9767\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.1595 - acc: 0.9769\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1629 - acc: 0.9756\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1649 - acc: 0.9744\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1649 - acc: 0.9758\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1567 - acc: 0.9772\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1513 - acc: 0.9790\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1539 - acc: 0.9779\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1491 - acc: 0.9789\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1581 - acc: 0.9778\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.1482 - acc: 0.9791\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1475 - acc: 0.9799\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.1429 - acc: 0.9805\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1356 - acc: 0.9824\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.1427 - acc: 0.9801\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1514 - acc: 0.9788\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1434 - acc: 0.9806\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1336 - acc: 0.9826\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1359 - acc: 0.9822\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.1393 - acc: 0.9811\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1384 - acc: 0.9814\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1373 - acc: 0.9819\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1308 - acc: 0.9837\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1296 - acc: 0.9828\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1366 - acc: 0.9824\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1250 - acc: 0.9844\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1307 - acc: 0.9829\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1248 - acc: 0.9841\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1339 - acc: 0.9822\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1302 - acc: 0.9837\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1236 - acc: 0.9850\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1284 - acc: 0.9832\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.1200 - acc: 0.9856\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1286 - acc: 0.9835\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1231 - acc: 0.9851\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1206 - acc: 0.9852\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1192 - acc: 0.9861\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.1137 - acc: 0.9862\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1289 - acc: 0.9829\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1223 - acc: 0.9855\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1174 - acc: 0.9862\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1184 - acc: 0.9855\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1187 - acc: 0.9862\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1138 - acc: 0.9862\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1177 - acc: 0.9857\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1163 - acc: 0.9866\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.1139 - acc: 0.9868\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1121 - acc: 0.9870\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.1103 - acc: 0.9876\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 0.1198 - acc: 0.9850\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.1132 - acc: 0.9867\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 0.1083 - acc: 0.9879\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1063 - acc: 0.9890\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1169 - acc: 0.9860\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 0.1138 - acc: 0.9871\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 10s 201us/step - loss: 0.1096 - acc: 0.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2373c6c26c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0907388064861299\n",
      "Test accuracy: 0.8112\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
